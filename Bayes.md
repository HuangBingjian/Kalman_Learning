1.贝叶斯法则

&emsp;&emsp;机器学习的任务：在给定训练数据D时，确定假设空间H中的最佳假设。

&emsp;&emsp;最佳假设：一种方法是把它定义为在给定数据D以及H中不同假设的先验概率的有关知识下的最可能假设。贝叶斯理论提供了一种计算假设概率的方法，基于假设的先验概率、给定假设下观察到不同数据的概率以及观察到的数据本身。

------

2.先验概率和后验概率

&emsp;&emsp;用P(h)表示在没有训练数据前假设h拥有的初始概率。P(h)被称为h的先验概率。先验概率反映了关于h是一正确假设的机会的背景知识如果没有这一先验知识，可以简单地将每一候选假设赋予相同的先验概率。类似地，P(D)表示训练数据D的先验概率，P(D|h)表示假设h成立时D的概率。机器学习中，我们关心的是P(h|D)，即给定D时h的成立的概率，称为h的后验概率。

------

3.贝叶斯公式

&emsp;&emsp;贝叶斯公式提供了从先验概率P(h)、P(D)和P(D|h)计算后验概率P(h|D)的方法

&emsp;&emsp;p(h|D)=P(D|H)*P(H)/P(D)

&emsp;&emsp;P(h|D)随着P(h)和P(D|h)的增长而增长，随着P(D)的增长而减少，即如果D独立于h时被观察到的可能性越大，那么D对h的支持度越小。

------

4.极大后验假设

&emsp;&emsp;学习器在候选假设集合H中寻找给定数据D时可能性最大的假设h，h被称为极大后验假设（MAP）确定MAP的方法是用贝叶斯公式计算每个候选假设的后验概率，计算式如下:

&emsp;&emsp;h_map=argmax P(h|D)=argmax (P(D|h)*P(h))/P(D)=argmax P(D|h)*p(h) (h属于集合H)

&emsp;&emsp;最后一步，去掉了P(D)，因为它是不依赖于h的常量。

------

5.极大似然假设

&emsp;&emsp;在某些情况下，可假定H中每个假设有相同的先验概率，这样式子可以进一步简化，只需考虑P(D|h)来寻找极大可能假设。

&emsp;&emsp;h_ml = argmax p(D|h)  h属于集合H

&emsp;&emsp;P(D|h)常被称为给定h时数据D的似然度，而使P(D|h)最大的假设被称为极大似然假设。

------

6.举例

&emsp;&emsp;考虑一个医疗诊断问题，有两种可能的假设：（1）病人有癌症。（2）病人无癌症。样本数据来自某化验测试，它也有两种可能的结果：阳性和阴性。假设我们已经有先验知识：在所有人口中只有0.008的人患病。此外，化验测试对有病的患者有98%的可能返回阳性结果，对无病患者有97%的可能返回阴性结果。

&emsp;&emsp;上面的数据可以用以下概率式子表示：

&emsp;&emsp;P(cancer)=0.008,P(无cancer)=0.992

&emsp;&emsp;P(阳性|cancer)=0.98,P(阴性|cancer)=0.02

&emsp;&emsp;P(阳性|无cancer)=0.03，P(阴性|无cancer)=0.97

&emsp;&emsp;假设现在有一个新病人，化验测试返回阳性，是否将病人断定为有癌症呢？我们可以来计算极大后验假设：

&emsp;&emsp;P(阳性|cancer)p(cancer)=0.98*0.008 = 0.0078

&emsp;&emsp;P(阳性|无cancer)*p(无cancer)=0.03*0.992 = 0.0298

&emsp;&emsp;因此，应该判断为无癌症。

&emsp;&emsp;确切的后验概率可将上面的结果归一化以使它们的和为1：

&emsp;&emsp;P(canner|+)=0.0078/(0.0078+0.0298)=0.21
&emsp;&emsp;P(cancer|-)=0.79

&emsp;&emsp;贝叶斯推理的结果很大程度上依赖于先验概率，另外不是完全接受或拒绝假设，只是在观察到较多的数据后增大或减小了假设的可能性。

------

&emsp;&emsp;贝叶斯分类具有如下特点：

&emsp;&emsp;(1)贝叶斯分类并不把一个对象绝对地指派给某一类，而是通过计算得出属于某一类的概率，具有最大概率的类便是该对象所属的类；

&emsp;&emsp;(2)一般情况下在贝叶斯分类中所有的属性都潜在地起作用，即并不是一个或几个属性决定分类，而是所有的属性都参与分类；

&emsp;&emsp;(3) 贝叶斯分类对象的属性可以是离散的、连续的，也可以是混合的。

&emsp;&emsp;贝叶斯定理给出了最小化误差的最优解决方法，可用于分类和预测。理论上，它看起来很完美，但在实际中，它并不能直接利用，它需要知道证据的确切分布概率，而实际上我们并不能确切的给出证据的分布概率。因此我们在很多分类方法中都会作出某种假设以逼近贝叶斯定理的要求。

&emsp;&emsp;（原文：https://www.cnblogs.com/burellow/archive/2013/03/19/2969538.html）
